%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amssymb}  % assumes amsmath package installed
%\usepackage{multirow}
\usepackage{color,colortbl}
\usepackage{graphicx}
\usepackage{amsmath,amssymb} % assumes amsmath package installed
\usepackage{algpseudocode}
\usepackage{subfigure}
%\usepackage{epsfig}
\usepackage{url}
\usepackage{cleveref}
%\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\newcommand{\etal}{et~al. }
\newcommand{\Kir}{K_{\text{IR}}}
\newcommand{\Krgb}{K_{\text{RGB}}}
\newcommand{\xir}{x_{\text{IR}}}
\newcommand{\xrgb}{x_{\text{RGB}}}
\newcommand{\Kdepth}{K_{\text{Depth}}}
\newcommand{\ba}{\mathbf{a}}
\newcommand{\ncomp}{N_{\mathrm{computers}}}
\newcommand{\njobs}{N_{\mathrm{jobs}}}
\newcommand{\atrial}{\ba_{\mathrm{trial}}}
\newcommand{\abest}{\ba_{\mathrm{best}}}
\newcommand{\ttrial}{t_{\mathrm{trial}}}
\newcommand{\tbest}{t_{\mathrm{best}}}
\newcommand{\itrial}{i_{\mathrm{trial}}}
\newcommand{\ntrials}{N_{\mathrm{trials}}}

\begin{document}

\title{\LARGE \bf
    Task Pipeline Specification and Scheduling
}

\author{John Schulman and Arjun Singh}

\maketitle
%\thispagestyle{empty}
%\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{abstract}
%
%In the past few years, significant progress has been made on the problem of
%instance recognition, in which a vision system must estimate the identity and
%pose of an object from a database of object instances. However, for many
%robotics purposes, such a system needs to be nearly perfect to work in the real
%world.  The state of the art in computer vision has rapidly advanced over the
%past decade largely due to the advent of fundamental image datasets such as
%MNIST, Caltech-101, PASCAL, and ImageNet.  However, these datasets are usually
%geared towards image retrieval tasks, as they often contain assorted collections
%of images from the web that do not enable pose recovery.  Furthermore, they do
%not examine what can actually be solved today by computer vision for robotic
%perception.  To address these issues, we present a high-quality,
%large-scale dataset of 3D object instances, with accurate calibration
%information for every image. We anticipate that ``solving'' this dataset will
%effectively remove many perception-related problems for mobile, sensing-based
%robots.
%
%While there exist several 3D datasets (e.g. Willow Garage, NYU V2,
%RGB-D Object Dataset, B3DO), they either only contain contain a small
%number of moderate-quality object models and/or scenes, lack some of the
%information a robot might have (such as calibration), or lack instance-level
%data.  We present four contributions: (1) a dataset of 100 objects (and
%growing), composed of 600 3D point clouds and 600 high-resolution (12 MP)
%images spanning all views of each object, (2) a bundle adjustment method for
%calibrating a multi-sensor system, (3) details of our data collection system,
%which collects all required data for a single object in under 6 minutes with
%minimal human effort, and (4) multiple software components, used to automate
%multi-sensor calibration and simplify the data collection process.
%
%\end{abstract}
\begin{abstract}
    Stuff
\end{abstract}

\section{Introduction}
We 

\section{Related Work}
Several other software packages have been created for the purpose of specifying dependency graphs of computational tasks and executing them in parallel.
Ruffus is a python library for specifying a computational pipeline \cite{goodstadt2010ruffus}.
It uses decorators to specify dependencies between these tasks.
Ruffus does not handle multi-computer parallelism.
Compmake \cite{censicompmake} is a new python-based tool that has make-like capabilities but enables parallel multi-computer execution of code.
One limitation of CompMake is TODO.

Optimal scheduling problems have been considered for a long time in the operations research community.
The problem we address here is most similar to \textit{job shop scheduling} \cite{yamada1997job}, whose formulation is that a set of identical machines must perform a set of tasks as fast as possible.
Some fast, special-purpose methods have been developed for this problem.
The communication aspect of our planning problem is not consider in job-shop scheduling, and it renders the special-purpose solution methods unusuable.


\section{Overview}
\section{Implementation}
\subsection{Task Specification}
\subsection{Pipeline Structure}
% TODO John -- partial

\subsection{Parallelization}

\section{Scheduling} \label{sec:scheduling}

\subsection{Problem Specification}

Given a set of tasks to perform, and a set of available computers, we would like to devise a plan of how to distribute the computation so as to minimize the time to completion.
The communication constraints present in this problem make it different from other scheduling problems that have been considered.
The computational operations produce large data files, so it is prudent to avoid transfering these files when possible because of the transfer time.
In particular, there are three limited resources of each computer: computation rate (i.e., number of CPUs), download bandwidth, and upload bandwidth.
A given computer can begin downloading a file that it needs for a future task while it is performing a previous task. 
In this section we formally define the scheduling problem and then propose an algorithm based on simulated annealing for optimizing the allocation of tasks to computers.

The inputs to the algorithm are the following:
\begin{itemize}
	\item Dependency graph, with a set of jobs, each of which has a set of inputs and outputs (inputs and outputs are typically files)
	\item Number of machines available for computation
	\item Specification of how long each computation and transport takes
\end{itemize}
The output is a set of tuples specifying computation and transport events.
\begin{itemize}
	\item Computation event: (job, location, start time, finish time)
	\item Transport event: (from loc., to loc., start time, finish time)
\end{itemize}
Tuples obey the following constraints:
\begin{itemize}
	\item A resource is only used after it arrives at a location
	\item Computation and bandwidth limits are respected by these intervals (k concurrent jobs per computer, only one upload and download at a time \footnote{This constraint can be relaxed at execution time, but makes planning and  simulation simpler})
	\item Final resources arrive at the master computer.
\end{itemize}



\subsection{Overview of Schduling Algorithm}


Our key simplifying assumption is as follows: given an assignment of jobs to computers, a near-optimal plan can be computed using a \textit{greedy controller}.
The greedy controller is defined to be a simple scheme for generating full plan (timing and ordering of events) given an assignment of jobs to computers
This controller can be straightforwardly be executed in real time, providing workers with jobs in response to completion messages.


Given this assumption, the planning problem is reduced to the problem of assigning jobs to computers. 
The timing and ordering of these jobs will be determined by the greedy controller.
As we will describe below, the planning algorithm we use is hill-climbing search on the assignment vector.

The greedy controller is defined as follows.
Whenever a job or transport event finishes, check to see if any new computation or transport events can be started
Computation: If all of the prerequisites for a job are present on a computer, start that job.
Transport: If a future job requires a resource but that resource is created on a different computer, AND the source and target computer are free to send and receive, respectively, start transporting that resource.
Can perform this check efficiently by only looking at frontier of computation graph

\subsection{Hill-Climbing Algorithm}

Hill-climbing (along with simulated annealing and related methods) is often used in planning problems that don't have the right structure to enable efficient exact solution methods \cite{glover2003handbook}. The below we how we hill-climbing search in the task we consider---scheduling computational tasks across a network.

Let $\ba$ denote an assignment vector of length $\njobs$, $a_i \in \{1,2,...,\ncomp\}$
Let $\operatorname{TotalTaskTime}(\ba)$ be the total task completion time that computed by simulating the greedy controller.
The algorithm is as follows:
\begin{algorithmic}
\State $\abest \gets [1, 1, \dots]$
\State $t_{\mathrm{best}} = \operatorname{TotalTaskTime}(\abest)$.
\For{$\itrial \gets 1,2,\dots,\ntrials$}
\State $\ba_{\mathrm{trial}} = \operatorname{copy}(\ba_{\mathrm{best}})$
\State Pick random element of $\atrial$, and set it to a random value.
\State Simulate executing greedy policy on $\atrial$, and compute total task time $\ttrial$.
\If{$\ttrial < \tbest$} 
	update $\tbest \gets \ttrial, \abest \gets \atrial$
\EndIf
\EndFor
\end{algorithmic}


\section{Results}
% TODO John -- partial

\section{Conclusions}


%\addtolength{\textheight}{-1cm}  % This command serves to balance the column lengths
%                                  % on the last page of the document manually. It shortens
%                                  % the textheight of the last page by a suitable amount.
%                                  % This command does not take effect until the next page
%                                  % so it should come on the page before the last. Make
%                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{references.bib}
\bibliographystyle{unsrt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
